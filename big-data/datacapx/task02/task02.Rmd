---
title: "Project Task 2"
output: github_document
---

https://rmarkdown.rstudio.com/lesson-9.html

# Import Libraries

```{r}
library(tidyverse)
library(pROC)
```

# --- Prepare the dataset and build a classifier

1.	Read in the reddit dataset correctly and provide evidence of your code. 

Read in the reddit dataset and select the brand_safe, num_crossposts and the six attributes - over_18, is_self, is_reddit_media_domain, is_video, stickied and spoiler - to form a data frame.

```{r}
# read the source csv file
reddit <- read.csv("RS_2017-09_filtered70.csv")
reddit <- as_tibble(reddit)

# select the subset of columns of interest
reddit.selection <- select(reddit, brand_safe, num_crossposts, over_18, is_self, is_reddit_media_domain, is_video, stickied, spoiler)

# summarize the data
reddit.selection %>%
  mutate_if(is.character, as.factor) %>%
  summary
```
All the columns except num_crossposts are Boolean values.

```{r}
# convert chatacter columns to boolean values
reddit.selection <- reddit.selection %>%
  mutate_if(is.character, as.logical)
```

2.	Build a classifier based on the six factors and provide the classifier information. Provide the correct analysis about the factors. 

- Build a classifier based on the six attributes to predict the brand_safe factor.
- Analyze the impact of the six input factors - Are those factors significant, and what is the impact of their value on the prediction?

```{r}
# split the data in training and testing data sets
reddit.selection <- reddit.selection %>%
  na.omit()

n <- dim(reddit.selection)[1]  
ind <- sample(c(TRUE, FALSE), n, replace=TRUE, prob=c(0.7, 0.3))

reddit.train <- reddit.selection[ind, ]
reddit.test <- reddit.selection[!ind, ]

# select the factors to include in the model
factors <- c("over_18", "is_self", "is_reddit_media_domain", "is_video", "stickied", "spoiler")
formula <- as.formula(paste("brand_safe ~ ", paste(factors, collapse="+")))

# build the base model
reddit.glm_base <- glm(formula, family=binomial(), reddit.train)

summary(reddit.glm_base)
```

- We can look at the coefficient significance (p.value). 
- All the factors used are significant. 
- The three variables over_18, is_self, and is_reddit_media_domain is the most significant in the model.
- The stickied variable appears to be have the least impact on the model and is a possible candidate for removal.
- These 3 variables has the highest prediction power and we should test if we can remove the other variables to get a simpler model.

```{r}
# factor significance
broom::tidy(reddit.glm_base) %>% filter(term != "(Intercept)") %>% arrange(p.value)
```

3.	Build a classifier based on the six factors and the additional factor. Provide the learned classifier information. Provide the correct comparison analysis between the built model and the model built in the previous step.

```{r}
# build a new model with num_crossposts as an additional factor
factors <- c("num_crossposts", "over_18", "is_self", "is_reddit_media_domain", "is_video", "stickied", "spoiler")
formula <- as.formula(paste("brand_safe ~ ", paste(factors, collapse="+")))
reddit.glm_crosspost <- glm(formula, family=binomial(), reddit.train)

summary(reddit.glm_crosspost)
```
```{r}
# factor significance
broom::tidy(reddit.glm_crosspost) %>% filter(term != "(Intercept)") %>% arrange(p.value)
```

- There is a reduction in deviance (overall quality of your model fit) for the second model.
- This value is not very large, so while the model will perform slightly better, the addition of the num_crossposts will not have a major impact.

```{r}
anova(reddit.glm_base, reddit.glm_crosspost, test="Chisq")
#anova(glm(brand_safe ~ num_crossposts, family=binomial(), reddit.train), reddit.glm_crosspost, test="Chisq")
```

# --- Model/feature selection

In this part, you will perform the model selection to reduce the six factors (over_18, is_self, is_reddit_media_domain, is_video, stickied, and spoiler) to three factors. You can use either "AIC" or "BIC" as the selection criterion.

-	Choose one model selection method to reduce the predictive factors from six to three. You will need to show:
-	Your three chosen factors.
-	The code used to calculate this result.
  - Your three chosen factors.
  - The code used to calculate this result.

1.	Perform model selection and produce the correct selection results. Provide your result and associated code.

```{r}
# select the top three significant factors
broom::tidy(reddit.glm_base) %>% 
  select(term, p.value) %>% 
  filter(term != "(Intercept)") %>% 
  arrange(p.value) %>%
  head(3)
```

```{r}
# build a new model with the 3 selected factors
factors <- c("over_18", "is_self", "is_reddit_media_domain")
formula <- as.formula(paste("brand_safe ~ ", paste(factors, collapse="+")))
reddit.glm_sigcoef <- glm(formula, family=binomial(), reddit.train)

summary(reddit.glm_sigcoef)
```

```{r}
# compare the models
anova(reddit.glm_base, reddit.glm_sigcoef, test="Chisq")
```
2.	Perform model selection using another method and produce the correct selection results. Provide your result and associated code

- performing the stepwise regression results in the formyla `brand_safe ~ over_18 + is_self + is_reddit_media_domain` after 3 steps which is the same set of factors selected in the previous step.

```{r}
# stepwise regression: forward selection
glm.null <- glm(brand_safe ~ 1, data=reddit.train)
step(glm.null, scope=list(upper=glm(brand_safe ~ ., data=reddit.train)), direction="forward")
```
# --- Verifying your chosen method

1.	Provide an appropriate definition of the criterion. Provide code to test the performance of the learned classifier. Compare it with the baseline method. Provide evidence of your code.

In this part, you will test the performance of a model in predicting new data. You will test the performance of both a classifier model you built earlier and a feature selection process.

- Define criteria that can be used to evaluate performance of a classifier model in predicting new data. Note that the criteria need to produce a single scalar indicating the performance of the classifier model. (Note: Based on the feedback you will receive from a University of Adelaide staff member, this may be different to the design phase.
- Provide the code you use to calculate the predictive performance of the classifier
- Compare your classifier with a naive baseline which predicts brand_safe as always True or False on the test data

```{r}
test_model <- function(factors, train, test) {
  # build the model
  formula <- as.formula(paste("brand_safe ~ ", paste(factors, collapse="+")))
  glm_model <- glm(formula, family=binomial(), train)

  # perform the predictions
  train$prediction <- predict(glm_model, type="response")
  test$prediction <- predict(glm_model, type="response", newdata=test)

  # return the formula and AUC value
  return (c(
    paste(factors, collapse="+"),
    round(auc(train$brand_safe, train$prediction), digits=5),
    round(auc(test$brand_safe, test$prediction), digits=5),
    round(glm_model$aic, digits=5)))
}

auc_results <- list(
  test_model(c("1"), reddit.train, reddit.test),
  test_model(c("over_18", "is_self", "is_reddit_media_domain"), reddit.train, reddit.test),
  test_model(c("over_18", "is_self", "is_reddit_media_domain", "is_video", "stickied", "spoiler"), reddit.train, reddit.test),
  test_model(c("num_crossposts", "over_18", "is_self", "is_reddit_media_domain", "is_video", "stickied", "spoiler"), reddit.train, reddit.test))

auc_results <- data.frame(matrix(unlist(auc_results), nrow=length(auc_results), byrow=TRUE))
colnames(auc_results) <- c("factors", "train.AUC", "test.AUC", "AIC")
auc_results
```

- The base model with no skill has an AUC of 0.5 as expected.
- The model with only the top 3 predictors perform only sighly worse than the 6 or 7 predictor variables models.
- Depending on the indented use the model might be useable, but is still not an very good model as can be verified by also looking at the ROC plot.

```{r}
# plot the ROC curces
plot_roc <- function(roc) {
  plot(roc, 
       print.auc=TRUE, 
       auc.polygon=TRUE,
       auc.polygon.col="lightblue", 
       print.thres=TRUE, print.thres.adj = c(1, -1),
       legacy.axes=FALSE,
       reuse.auc=FALSE)
}

reddit.glm_sigcoef_roc  <- roc(reddit.test$brand_safe, predict(reddit.glm_sigcoef, type="response", newdata=reddit.test), curve=TRUE)
plot_roc(reddit.glm_sigcoef_roc)
```



```{r}
# create the roc for a naive model always prediting trye
#n <- dim(reddit.test)[1]
#pred <- c(rep(1, n))
#reddit.naive_roc <- roc(reddit.test$brand_safe, pred, curve=TRUE)

# calculate the roc values
#reddit.naive_roc <- roc(reddit.test$brand_safe, predict(glm.null, type="response", newdata=reddit.test), curve=TRUE)
#reddit.glm_base_roc <- roc(reddit.train$brand_safe, predict(reddit.glm_base, type="response", newdata=reddit.train), #curve=TRUE)
#reddit.glm_sigcoef_roc  <- roc(reddit.train$brand_safe, predict(reddit.glm_sigcoef, type="response", newdata=reddit.train), curve=TRUE)

#plot_roc(reddit.naive_roc)
#plot_roc(reddit.glm_base_roc)
#plot_roc(reddit.glm_sigcoef_roc)

```

2.	Perform feature/model selection with the criterion developed in Step 1 of Verifying your chosen method. Conclude whether the selection results are the same as those in Model/feature selection. Provide your selection results and associated code. Provide your selection results and associated code.  

- The idea is to apply a manual method similar to stepwise regression, forward selection by adding a variable at each step that increases to model predictive power the most.
- Instead of looking at AIC as before, the AUC value will be considered derived from the predicted values.

```{r}
# step 1 - select the first variable with the most impact
auc_results <- list(
  test_model(c("num_crossposts"), reddit.train, reddit.test),
  test_model(c("over_18"), reddit.train, reddit.test),
  test_model(c("is_self"), reddit.train, reddit.test),
  test_model(c("is_reddit_media_domain"), reddit.train, reddit.test),
  test_model(c("is_video"), reddit.train, reddit.test),
  test_model(c("stickied"), reddit.train, reddit.test),
  test_model(c("spoiler"), reddit.train, reddit.test))

auc_results <- data.frame(matrix(unlist(auc_results), nrow=length(auc_results), byrow=TRUE))
colnames(auc_results) <- c("factors", "train.AUC", "test.AUC", "AIC")

auc_results %>%
  arrange(desc(train.AUC))
```

```{r}
# step 2 - is_self as first variable
auc_results <- list(
  test_model(c("is_self", "num_crossposts"), reddit.train, reddit.test),
  test_model(c("is_self", "over_18"), reddit.train, reddit.test),
  test_model(c("is_self", "is_reddit_media_domain"), reddit.train, reddit.test),
  test_model(c("is_self", "is_video"), reddit.train, reddit.test),
  test_model(c("is_self", "stickied"), reddit.train, reddit.test),
  test_model(c("is_self", "spoiler"), reddit.train, reddit.test))

auc_results <- data.frame(matrix(unlist(auc_results), nrow=length(auc_results), byrow=TRUE))
colnames(auc_results) <- c("factors", "train.AUC", "test.AUC", "AIC")

auc_results %>%
  arrange(desc(train.AUC))
```

```{r}
# step 3 - over_18 as second variable
auc_results <- list(
  test_model(c("is_self", "over_18", "num_crossposts"), reddit.train, reddit.test),
  test_model(c("is_self", "over_18", "is_reddit_media_domain"), reddit.train, reddit.test),
  test_model(c("is_self", "over_18", "is_video"), reddit.train, reddit.test),
  test_model(c("is_self", "over_18", "stickied"), reddit.train, reddit.test),
  test_model(c("is_self", "over_18", "spoiler"), reddit.train, reddit.test))

auc_results <- data.frame(matrix(unlist(auc_results), nrow=length(auc_results), byrow=TRUE))
colnames(auc_results) <- c("factors", "train.AUC", "test.AUC", "AIC")

auc_results %>%
  arrange(desc(train.AUC))
```

